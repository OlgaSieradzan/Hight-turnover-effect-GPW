{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obliczanie zwrotu z inwestycji\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tej części projektu, na podstawie sygnałów generwanych przez poprzedni kod pythona obliczone zostaną dzienne stopy zwrotu z rozważanych strategii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BIBLIOTEKI ###\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### ŚCIEŻKI ##\n",
    "file_path1 = \"C:/Users/olgas/OneDrive/Documents/GitHub/Hight-turnover-effect-GPW/rates_data/rates_data.xlsx\"\n",
    "file_path2 = \"C:/Users/olgas/OneDrive/Documents/GitHub/Hight-turnover-effect-GPW/prices_cleaned.xlsx\"\n",
    "file_path3 = \"C:/Users/olgas/OneDrive/Documents/GitHub/Hight-turnover-effect-GPW/GPW capitalization USD mies.xlsx\"\n",
    "file_path4 = \"C:/Users/olgas/OneDrive/Documents/GitHub/Hight-turnover-effect-GPW/zestawienie nazw.xlsx\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytywanie danych\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sygnały są zapisane w 15 strategiach (każda w osobnym arkuszu w pliku excel). Odczytuje wszytskiie do słownika ramek danych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olgas\\AppData\\Local\\Temp\\ipykernel_19352\\322302912.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  prices.iloc[:, 1:] = prices.iloc[:, 1:].applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n"
     ]
    }
   ],
   "source": [
    "prices = pd.read_excel(file_path2)\n",
    "\n",
    "prices.iloc[:, 1:] = prices.iloc[:, 1:].applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "\n",
    "capitalization = pd.read_excel(file_path3)\n",
    "\n",
    "accuracy = pd.read_excel(file_path4)\n",
    "\n",
    "\n",
    "sheets_dict = pd.read_excel(file_path1, sheet_name=None)\n",
    "\n",
    "sygnals = {} # Pusty słownik do zappisywania \n",
    "for sheet_name, dataframe in sheets_dict.items():\n",
    "    sygnals[sheet_name] = dataframe\n",
    "\n",
    "# Odwoływanie sie do konkretnych ramek danych -> sygnals['rates_10_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dzienne stopy zwrotu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_returns(df):\n",
    "    result = pd.DataFrame(columns=df.columns)  # Nowa ramka danych do przechowywania wyników\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col == 'Date':\n",
    "            \n",
    "            result['Date'] = df['Date'][1:].reset_index(drop=True)\n",
    "        else:\n",
    "            # Oblicz dzienne stopy zwrotu\n",
    "            rates_values = []  # Pusta lista na dzienne stopy zwrotu\n",
    "            for i in range(len(df) - 1):\n",
    "                rate = (df[col].iloc[i + 1] - df[col].iloc[i]) / df[col].iloc[i]\n",
    "                rates_values.append(rate)  # Dodaj wynik do listy\n",
    "\n",
    "            result[col] = pd.Series(rates_values).reset_index(drop=True)\n",
    "\n",
    "    return result\n",
    "\n",
    "daily_returns_df = daily_returns(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ujednolicenie kolumn \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W badaniu potrzeba ujednolicić kolumny w ramkach danych z kapitalizacją i cenami i sygnałami\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = accuracy.loc[accuracy['czy zgodnosc'].isnull(), 'Profesora'].tolist() # Kolumny których nie ma w mojej tabeli do usuniecia \n",
    "\n",
    "capitalizationv2 = capitalization.drop(columns=columns_to_remove) # usunięcie wartości których ja u siebie nie mam \n",
    "\n",
    "capitalizationv3 = capitalizationv2[prices.columns] # ustawienie w tej samej kolejności kolumny\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Okres inwestycji - 1 dzień \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W przypadku okresu sprzedaży równego 1 dzień, nie trzeba liczyć średnich dziennych stóp zwrotu z uwzględnieniem tego okresu \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_day(sygnal_df, prices_df, price, kap_min, kap_df, daily_returns):\n",
    "\n",
    "    \n",
    "    # Upewnij się, że wszystkie daty są w formacie datetime\n",
    "    sygnal_df['Year'] = pd.to_datetime(sygnal_df['Date']).dt.year\n",
    "    sygnal_df['Month'] = pd.to_datetime(sygnal_df['Date']).dt.month\n",
    "    kap_df['Year'] = pd.to_datetime(kap_df['Date']).dt.year\n",
    "    kap_df['Month'] = pd.to_datetime(kap_df['Date']).dt.month\n",
    "\n",
    "    # Dołącz kapitalizację na podstawie roku i miesiąca\n",
    "    kap_df = kap_df.drop(columns=['Date'])  # Usuń oryginalną kolumnę Date, aby uniknąć konfliktów\n",
    "    merged_df = pd.merge(\n",
    "        sygnal_df,\n",
    "        kap_df,\n",
    "        on=['Year', 'Month'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    sygnal_df = sygnal_df.drop(columns=['Year', 'Month'])\n",
    "\n",
    "    # Filtrowanie ramek\n",
    "    filtered_kap = [col for col in merged_df.columns if col.endswith('_y')]\n",
    "    filtered_kap = merged_df[filtered_kap]\n",
    "    filtered_prices = prices_df.loc[sygnal_df.index]\n",
    "\n",
    "    # Pusta ramka na wyniki\n",
    "    result = pd.DataFrame(columns=['Date', 'Mean', 'Count'])\n",
    "\n",
    "\n",
    "    # Iteracja po wierszach\n",
    "    for i in range(len(sygnal_df)):\n",
    "        row_sum = 0\n",
    "        count = 0\n",
    "\n",
    "        for col in sygnal_df.columns:\n",
    "            if col == 'Date':\n",
    "                result.loc[i, 'Date'] = sygnal_df.loc[i, 'Date']\n",
    "            else:\n",
    "                if not pd.isna(sygnal_df[col].iloc[i]):\n",
    "\n",
    "                    # Sprawdzamy, czy kolumna istnieje w filtered_prices\n",
    "                    if col in filtered_prices.columns:\n",
    "                        # Pobieramy odpowiednią wartość kapitalizacji dla konkretnego wiersza\n",
    "                        kap_value = filtered_kap.loc[i, col + '_y']\n",
    "\n",
    "                        # Sprawdzamy warunki ceny i kapitalizacji\n",
    "                        if (filtered_prices[col].iloc[i] > price and\n",
    "                                kap_min <= kap_value and pd.notna(kap_value)):\n",
    "                            row_sum += daily_returns[col].iloc[i]\n",
    "                            count += 1\n",
    "                    else:\n",
    "                        print(f\"Kolumna {col} nie istnieje w filtered_prices, pomijam wiersz {i}\")\n",
    "\n",
    "        # Obliczanie średniej i zapis wyników\n",
    "        mean = row_sum / count if count > 0 else 0\n",
    "        result.loc[i, 'Mean'] = mean\n",
    "        result.loc[i, 'Count'] = count\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_50_1_v2 = one_day(sygnals['rates_50_1'], prices, 0, 0, capitalizationv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = sygnals['rates_50_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teścik\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spółki powyżej cen 1 zł około \n",
    "results_10_1_v1 = one_day(sygnals['rates_10_1'], prices, 0.25, 0, capitalizationv2)\n",
    "results_20_1_v1 = one_day(sygnals['rates_20_1'], prices, 0.25, 0, capitalizationv2)\n",
    "results_50_1_v1 = one_day(sygnals['rates_50_1'], prices, 0.25, 0, capitalizationv2)\n",
    "# Spółki powyżej cen 2 zł około \n",
    "results_10_1_v2 = one_day(sygnals['rates_10_1'], prices, 0.5, 0, capitalizationv2)\n",
    "results_20_1_v2 = one_day(sygnals['rates_20_1'], prices, 0.5, 0, capitalizationv2)\n",
    "results_50_1_v2 = one_day(sygnals['rates_50_1'], prices, 0.5, 0, capitalizationv2)\n",
    "# Kap większa niż 1000000\n",
    "results_10_1_v3 = one_day(sygnals['rates_10_1'], prices, 0.25, 1000000, capitalizationv2)\n",
    "results_20_1_v3 = one_day(sygnals['rates_20_1'], prices, 0.25, 1000000, capitalizationv2)\n",
    "results_50_1_v3 = one_day(sygnals['rates_50_1'], prices, 0.25, 1000000, capitalizationv2)\n",
    "# Kap wieksze niż 2000000\n",
    "results_10_1_v4 = one_day(sygnals['rates_10_1'], prices, 0.25, 2000000, capitalizationv2)\n",
    "results_20_1_v4 = one_day(sygnals['rates_20_1'], prices, 0.25, 2000000, capitalizationv2)\n",
    "results_50_1_v4 = one_day(sygnals['rates_50_1'], prices, 0.25, 2000000, capitalizationv2)\n",
    "# Kap wieksze niz 5000000\n",
    "results_10_1_v5 = one_day(sygnals['rates_10_1'], prices, 0.25, 5000000, capitalizationv2)\n",
    "results_20_1_v5 = one_day(sygnals['rates_20_1'], prices, 0.25, 5000000, capitalizationv2)\n",
    "results_50_1_v5 = one_day(sygnals['rates_50_1'], prices, 0.25, 5000000, capitalizationv2)\n",
    "# Kap wieksze niż 10000000\n",
    "results_10_1_v3 = one_day(sygnals['rates_10_1'], prices, 0.25, 10000000, capitalizationv2)\n",
    "results_20_1_v3 = one_day(sygnals['rates_20_1'], prices, 0.25, 10000000, capitalizationv2)\n",
    "results_50_1_v3 = one_day(sygnals['rates_50_1'], prices, 0.25, 10000000, capitalizationv2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okres inwestycji, 5 dni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_day(sygnal_df, prices_df, price, kap_min, kap_df, daily_returns):\n",
    "\n",
    "    \n",
    "    # Upewnij się, że wszystkie daty są w formacie datetime\n",
    "    sygnal_df['Year'] = pd.to_datetime(sygnal_df['Date']).dt.year\n",
    "    sygnal_df['Month'] = pd.to_datetime(sygnal_df['Date']).dt.month\n",
    "    kap_df['Year'] = pd.to_datetime(kap_df['Date']).dt.year\n",
    "    kap_df['Month'] = pd.to_datetime(kap_df['Date']).dt.month\n",
    "\n",
    "    # Dołącz kapitalizację na podstawie roku i miesiąca\n",
    "    kap_df = kap_df.drop(columns=['Date'])  # Usuń oryginalną kolumnę Date, aby uniknąć konfliktów\n",
    "    merged_df = pd.merge(\n",
    "        sygnal_df,\n",
    "        kap_df,\n",
    "        on=['Year', 'Month'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    sygnal_df = sygnal_df.drop(columns=['Year', 'Month'])\n",
    "\n",
    "    # Filtrowanie ramek\n",
    "    filtered_kap = [col for col in merged_df.columns if col.endswith('_y')]\n",
    "    filtered_kap = merged_df[filtered_kap]\n",
    "    filtered_prices = prices_df.loc[sygnal_df.index]\n",
    "\n",
    "    # Pusta ramka na wyniki\n",
    "    result = pd.DataFrame(columns=['Date', 'Mean', 'Count'])\n",
    "    mid_results = pd.DataFrame (columns = ['Date', 's1', \"s2\", 's3','s4', 's5', 's1_c', \"s2_c\", 's3_c','s4_c', 's5_c'] )\n",
    "    mid_results['Date'] = sygnal_df.loc[1:, 'Date' ]\n",
    "\n",
    "    print(mid_results)\n",
    "    # Iteracja po wierszach\n",
    "    for i in range(4):\n",
    "\n",
    "        for j in range(i, len(sygnal_df)):\n",
    "\n",
    "            \n",
    "            count = 0\n",
    "            cols = [] # lista na nazwy kolumn ( nowa w każdej iteracji )\n",
    "\n",
    "            for col in sygnal_df.columns:\n",
    "                if col != 'Date':\n",
    "                    if not pd.isna(sygnal_df[col].iloc[j]):\n",
    "\n",
    "                        # Sprawdzamy, czy kolumna istnieje w filtered_prices\n",
    "                        if col in filtered_prices.columns:\n",
    "                            # Pobieramy odpowiednią wartość kapitalizacji dla konkretnego wiersza\n",
    "                            kap_value = filtered_kap.loc[i, col + '_y']\n",
    "\n",
    "                            # Sprawdzamy warunki ceny i kapitalizacji\n",
    "                            if (filtered_prices[col].iloc[i] > price and\n",
    "                                    kap_min <= kap_value and pd.notna(kap_value)):\n",
    "                                cols.append(col)\n",
    "                                count += 1\n",
    "                        else:\n",
    "                            print(f\"Kolumna {col} nie istnieje w filtered_prices, pomijam wiersz {i}\")\n",
    "                \n",
    "            column_name = f's{i+1}' \n",
    "            counter_column = f's{i+1}_c'\n",
    "\n",
    "\n",
    "            for k in range(4) :\n",
    "                # Obliczanie średniej i zapis wyników\n",
    "                print(mid_results)\n",
    "                print(j)\n",
    "                print(i)\n",
    "                print(column_name)\n",
    "                print(counter_column)\n",
    "                \n",
    "                mean = daily_returns.loc[j+k,cols].sum() / count if count > 0 else 0\n",
    "                print(mean)\n",
    "                mid_results.loc[j+k, column_name] = mean\n",
    "                mid_results.loc[j+k, counter_column] = count\n",
    "        j += 5 \n",
    "\n",
    "\n",
    "    result['Date'] = mid_results['Date']\n",
    "    result['Mean'] = mid_results[['s1', 's2', 's3', 's4', 's5']].mean(axis=1, skipna=True)\n",
    "    result['Count'] = mid_results[['s1_c', 's2_c', 's3_c', 's4_c', 's5_c']].sum(axis=1, skipna=True)\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_day(sygnals['rates_10_5'], prices, 0, 0, capitalizationv2, daily_returns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skumulowane stopy zwrotu \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_return = (1 + pd.Series(returns)).prod() - 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
